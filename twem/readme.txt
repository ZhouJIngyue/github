数据来源于 https://competitions.codalab.org/competitions/17344#learn_the_details
tweetUS.txt.text是一个文本文档，共有493688行，一行是一句话，代表一条微博.
tweetUS.txt.labels也是一个文本文档，共有493688行，一行是一个数字，代表tweetUS.txt.text对应那行微博中出现的表情.

想要达到的目标是，写一个程序，输入是一句话，例如LoL @ West Covina, California.
输出是一个类别，例如2，代表程序预测该微博中会出现的表情.
希望从微博上拉一条带表情的数据过来，把文本作为输入，程序能预测出对应的表情.

要用这五万条数据，构建模型并评价它，一个样例流程如下：
1.把五万条数据分成训练集和测试集.
2.用训练集构建模型，模型的输入是一句话，输出是一个类别.
3.将测试集的文本作为模型的输入，比较模型输出类别与测试集类别的相似度，用以评价模型.

1，3都很容易理解.
主要是2，方法很多，举一个简单的例子：
2.1统计训练集文本中出现的所有词.
2.2对每一个词i，统计一条文本中出现该词后，该条文本归属于每个类别j的概率Pij.
    Pij=(包含词i且属于类别j的文本条数+1)/(包含词i的文本条数+类别数).
2.3对于一条要预测的文本，设其中出现的词为(k1,k2...)属于K，该文本属于类别j的可能性Cj可以这样计算.
    Cj=连乘(k属于K)Pkj.
2.4输出C中最大值对应的类别.

以上便是一个完整的实现流程，由于丢弃了词与词之间的关联，顺序，估计效果不会好.
现在比较热的模型，可以处理顺序输入的有循环神经网络，其中LSTM据说效果不错，看过些资料，暂时还是一知半解.
慢慢学呗，边做边学.